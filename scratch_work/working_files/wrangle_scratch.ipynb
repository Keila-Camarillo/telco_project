{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa48ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# tree classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# rainforest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# linear regession classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import wrangle as w\n",
    "import explore as e \n",
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2212d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_telco_data(directory=os.getcwd(), filename=\"telco_churn.csv\"):\n",
    "#     \"\"\"\n",
    "#     This function searches the local directory for the csv file and returns if exists.\n",
    "#     However, if csv doesn't exists it will create a df of the predefined SQL_query and write the df to csv.\n",
    "#     This function is currently set to output the telco_churn df from the current working directory.\n",
    "# \"\"\"\n",
    "#     SQL_query = ''' select * from customers\n",
    "#                     left join contract_types\n",
    "#                     using (contract_type_id)\n",
    "#                     left join customer_churn\n",
    "#                     using (customer_id)\n",
    "#                     left join customer_signups\n",
    "#                     using (customer_id)\n",
    "#                     join internet_service_types\n",
    "#                     using (internet_service_type_id)\n",
    "#                     join payment_types\n",
    "#                     using (payment_type_id);\n",
    "# '''\n",
    "\n",
    "#     if os.path.exists(directory + filename):\n",
    "#         df = pd.read_csv(filename) \n",
    "#         return df\n",
    "    \n",
    "#     else:\n",
    "#         df = pd.read_sql(SQL_query, env.get_db_url('telco_churn'))\n",
    "# #         df = new_telco_data(SQL_query)\n",
    "        \n",
    "#         #want to save to csv\n",
    "#         df.to_csv(filename)\n",
    "#         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372241fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # acquiring, cleaning, and adding features to data\n",
    "df = w.prep_telco()\n",
    "# df = w.prep_telco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with customer id\n",
    "def prep_telco2(df=get_telco_data(directory=os.getcwd())):\n",
    "    '''\n",
    "    The function will clean the telco dataset with features prior to explore.\n",
    "    The function will also return to dataframes:\n",
    "    '''\n",
    "    # encoding payment type automatic payment equals 1 and non_automatic equals 0\n",
    "    df[\"automatic_payment\"] = df[\"payment_type\"].map({\"Bank transfer (automatic)\": 1, \"Credit card (automatic)\": 1, \"Mailed check\": 0, \"Electronic check\": 0})\n",
    "\n",
    "    # create dummies\n",
    "    dummy_df = pd.get_dummies(df[[\"partner\",\n",
    "                                 \"dependents\", \n",
    "                                 \"paperless_billing\", \n",
    "                                 \"gender\",\n",
    "                                 \"churn\"]],\n",
    "                              drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    # rename columns\n",
    "    df = df[[\"customer_id\",\"partner_Yes\", \"dependents_Yes\", \"paperless_billing_Yes\", \"automatic_payment\", \"churn_Yes\", \"gender_Male\", \"tenure\"]]\n",
    "    \n",
    "    df = df.rename(columns={\"partner_Yes\": \"partner\", \"dependents_Yes\": \"dependents\", \"paperless_billing_Yes\": \"paperless_billing\",  \"gender_Male\": \"gender\",\"churn_Yes\": \"churn\"})\n",
    "    # df for modeling\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1270ffbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>paperless_billing</th>\n",
       "      <th>automatic_payment</th>\n",
       "      <th>churn</th>\n",
       "      <th>tenure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      partner  dependents  paperless_billing  automatic_payment  churn  tenure\n",
       "0           1           1                  1                  0      0       9\n",
       "1           0           0                  0                  0      0       9\n",
       "2           0           0                  1                  0      1       4\n",
       "3           1           0                  1                  0      1      13\n",
       "4           1           0                  1                  0      1       3\n",
       "...       ...         ...                ...                ...    ...     ...\n",
       "7038        0           0                  0                  0      0      13\n",
       "7039        1           0                  1                  0      1      22\n",
       "7040        0           0                  1                  0      0       2\n",
       "7041        1           1                  0                  0      0      67\n",
       "7042        1           1                  0                  0      0      63\n",
       "\n",
       "[7043 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81982e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, va, tt = w.split_data(df, \"churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "275ca660",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('customer_id', '')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('customer_id', '')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bf/lhpb5n_j1xj4msxy6nrm9h7h0000gn/T/ipykernel_18722/333600844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"customer_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('customer_id', '')"
     ]
    }
   ],
   "source": [
    "df[\"customer_id\", \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d01ae",
   "metadata": {},
   "source": [
    "# Summarize df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with only selected and tested features\n",
    "df_2 = w.prep_telco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be62190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about df, such as column names, rows, datatypes, non-missing values\n",
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef03c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for numeric columns.\n",
    "df_2.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38060d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .describe with object columns.\n",
    "\n",
    "obj_cols = df.columns[[df[col].dtype == 'O' for col in df.columns]]\n",
    "for col in obj_cols:\n",
    "    print(df[col].value_counts())\n",
    "    print(df[col].value_counts(normalize=True, dropna=False))\n",
    "    print('----------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .describe with object columns.\n",
    "\n",
    "obj_cols_2 = df_2.columns[[df_2[col].dtype == 'O' for col in df_2.columns]]\n",
    "for col in obj_cols_2:\n",
    "    print(df_2[col].value_counts())\n",
    "    print(df_2[col].value_counts(normalize=True, dropna=False))\n",
    "    print('----------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with nulls and the total of missing values.\n",
    "missing = df_2.isnull().sum()\n",
    "missing[missing > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8672770",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a74c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates, reassign and check the shape of df. *No change to df shape\n",
    "df = df.drop_duplicates()\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0541278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding payment type automatic payment equals 1 and non_automatic equals 0\n",
    "df[\"payment_encoded\"] = df.payment_type.map({\"Bank transfer (automatic)\": 1, \"Credit card (automatic)\": 1, \"Mailed check\": 0, \"Electronic check\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93925c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning column names for easier recall and because it's formal\n",
    "df1 = df1.rename(columns={\"partner_Yes\": \"partner\", \"dependents_Yes\": \"dependents\", \"paperless_billing_Yes\": \"paperless_billing\", \"payment_encoded\": \"automatic_payment\", \"churn_Yes\": \"churn\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f76135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.payment_encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559df41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.payment_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3262204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2[[\"partner\", \"dependents\", \"paperless_billing\", \"automatic_payment\", \"churn\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_telco(df):\n",
    "    '''\n",
    "    The function will clean the telco dataset.\n",
    "    The function will also return to dataframes:\n",
    "    '''\n",
    "    # encoding payment type automatic payment equals 1 and non_automatic equals 0\n",
    "    df[\"automatic_payment\"] = df[\"payment_type\"].map({\"Bank transfer (automatic)\": 1, \"Credit card (automatic)\": 1, \"Mailed check\": 0, \"Electronic check\": 0})\n",
    "\n",
    "    # create dummies\n",
    "    dummy_df = pd.get_dummies(df[[\"partner\",\n",
    "                                 \"dependents\", \n",
    "                                 \"paperless_billing\", \n",
    "                                 \"churn\",\n",
    "                                 \"gender\"]],\n",
    "                              drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    # rename columns\n",
    "    df = df[[\"customer_id\",\"partner_Yes\", \"dependents_Yes\", \"paperless_billing_Yes\", \"automatic_payment\", \"churn_Yes\", \"gender_Male\"]]\n",
    "    \n",
    "    df = df.rename(columns={\"partner_Yes\": \"partner\", \"dependents_Yes\": \"dependents\", \"paperless_billing_Yes\": \"paperless_billing\", \"churn_Yes\": \"churn\"})\n",
    "    # df for modeling\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = prep_telco(df)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c6ff9f",
   "metadata": {},
   "source": [
    "# Split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb66c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aee8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original split data\n",
    "train, validate, test = w.split_data(df_2,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b69fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_pred = pd.concat([tt, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "train_2, validate_2, test_2 = w.split_data(df_2,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate split.\n",
    "def valid_split(train, validate, test):\n",
    "    print(f'train -> {train.shape}')\n",
    "    print(f'validate -> {validate.shape}')\n",
    "    print(f'test -> {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8babce",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_split(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ed1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_split(train_2, validate_2, test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78417b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ac6ff",
   "metadata": {},
   "source": [
    "# How often are customers churning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.churn.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def churn_pie():\n",
    "    y = train.churn.value_counts(normalize=True)\n",
    "\n",
    "    mylabels = [\"Did Not Churn\", \"Did Churn\"]\n",
    "\n",
    "    plt.pie(y, labels = mylabels, autopct='%1.1f%%')\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.churn_pie(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f2b28",
   "metadata": {},
   "source": [
    "# QUESTION 1: Do customers that have an automatic payment type more or less likely to churn?\n",
    "\n",
    "* What's the relationship between churn and payment type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"What's the Relationship Between Churn and Automatic Payment Type?\")\n",
    "sns.barplot(x=\"automatic_payment\", y=\"churn\", data=train)\n",
    "population_churn_rate = train.churn.mean()\n",
    "plt.axhline(population_churn_rate, label=\"Population Churn Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a crosstab of observed survival to pclass\n",
    "def cross_function(train, target_variable, feature_variable, null_hypothesis, alternative_hypothesis):\n",
    "    '''\n",
    "    This function will take the train df, target_variable, and feature_variable\n",
    "    '''\n",
    "    observed = pd.crosstab(train[target_variable], train[feature_variable])\n",
    "\n",
    "    chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "    if p < alpha:\n",
    "        print(f\"Reject the null hypothesis: {null_hypothesis}\")\n",
    "        print(f\"Sufficient evidence to move forward understanding that, {alternative_hypothesis}\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null\")\n",
    "        print(\"Insufficient evidence to reject the null\")\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb138f9e",
   "metadata": {},
   "source": [
    "Do customers that have an automatic payment type more or less likely to churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccff070",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_Q1 = 0.05\n",
    "target_Q1 = \"churn\"\n",
    "feature_variable_Q1 = \"automatic_payment\"\n",
    "null_hypothesis_Q1 = \"churn and automatic payment are independent\"\n",
    "alternative_hypothesis_Q1 = \"there is a relationship between automatic payment and churn\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dcff9d",
   "metadata": {},
   "source": [
    "# Question 2:  Do customers that have paperless billing more or less likely to churn?\n",
    "* What's the relationship between churn and paperless billing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"What's the Relationship Between Churn and paperless billing?\")\n",
    "sns.barplot(x=\"paperless_billing\", y=\"churn\", data=train)\n",
    "population_churn_rate = train.churn.mean()\n",
    "plt.axhline(population_churn_rate, label=\"Population Churn Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi squared to compare proportions, define confidence\n",
    "alpha_Q2 = 0.05\n",
    "target_Q2 = \"churn\"\n",
    "feature_variable_Q2 = \"paperless_billing\"\n",
    "null_hypothesis_Q2 = \"churn and paperless_billing are independent\"\n",
    "alternative_hypothesis_Q2 = \"there is a relationship between paperless_billing and churn\"\n",
    "\n",
    "e.cross_function(train, target, feature_variable_Q2, null_hypothesis_Q2, alternative_hypothesis_Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a649181",
   "metadata": {},
   "source": [
    "# Question 3: Do customers that have partner more or less likely to churn?\n",
    "* What's the relationship between churn and customers' with partners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"What's the Relationship Between Churn and Customers' with Partners\")\n",
    "sns.barplot(x=\"partner\", y=\"churn\", data=train)\n",
    "population_churn_rate = train.churn.mean()\n",
    "plt.axhline(population_churn_rate, label=\"Population Churn Rate\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "def relationship_churn(train, graph_title, feature, target):\n",
    "    '''\n",
    "    This function will take the train, graph_title, feature, and target,\n",
    "    and it will display a bargraph based on the information provided for the churn dataset \n",
    "\n",
    "    '''\n",
    "    fig, ax =plt.subplots()\n",
    "    plt.title(graph_title)\n",
    "    sns.barplot(x=feature, y=target, data=train)\n",
    "    population_churn_rate = train.churn.mean()\n",
    "\n",
    "    tick_label = [\"No\", \"Yes\"]\n",
    "    ax.set_xticklabels(tick_label)\n",
    "    # sns.distplot(train)\n",
    "\n",
    "    plt.axhline(population_churn_rate, label=\"Population Churn Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe63906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_churn(train, \"What's the Relationship Between Churn and Customers' with Partners\", feature_variable_Q2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71dba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi squared to compare proportions, define confidence\n",
    "alpha_Q3 = 0.05\n",
    "target_Q3 = \"churn\"\n",
    "feature_variable_Q3 = \"partner\"\n",
    "null_hypothesis_Q3 = \"churn and customers' with partners are independent\"\n",
    "alternative_hypothesis_Q3 = \"there is a relationship between customers' with partners and churn\"\n",
    "\n",
    "e.cross_function(train, target, feature_variable_Q3, null_hypothesis_Q3, alternative_hypothesis_Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d8f2a",
   "metadata": {},
   "source": [
    "# Question 4: Do customers that have dependents more or less likely to churn?\n",
    "* What's the relationship between churn and customers' with dependents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea32023",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"What's the Relationship Between Churn and Customers' with Dependents\")\n",
    "sns.barplot(x=\"dependents\", y=\"churn\", data=train)\n",
    "population_churn_rate = train.churn.mean()\n",
    "plt.axhline(population_churn_rate, label=\"Population Churn Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83435740",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_Q4 = 0.05\n",
    "target_Q4 = \"churn\"\n",
    "feature_variable_Q4 = \"dependents\"\n",
    "null_hypothesis_Q4 = \"churn and customers' with dependents are independent\"\n",
    "alternative_hypothesis_Q4 = \"there is a relationship between customers' with dependents and churn\"\n",
    "\n",
    "e.cross_function(train, target, feature_variable_Q4, null_hypothesis_Q4, alternative_hypothesis_Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918897ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: What's the relationship between churn and gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcc2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_title_Q5 = \"What's the Relationship Between Churn and Customers' with Dependents\"\n",
    "feature_Q5 = \"gender\"\n",
    "\n",
    "e.relationship_churn(train, graph_title_Q5, feature_Q5, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a578c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "**I will use chi-square to investigate the relationship between churning and gender**\n",
    "\n",
    "* I will use a confidence interval of 95%\n",
    "* The alpha is .05\n",
    "\n",
    "\n",
    "* $H_o$: 'Churn' and 'Gender' are independent.\n",
    "* $H_a$: 'Churn' and 'Gender' are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_hypothesis_Q5 = \"'Churn' and 'Gender' are independent.\"\n",
    "alternative_hypothesis_Q5 = \"'Churn' and 'Gender' are related.\"\n",
    "\n",
    "e.cross_function(train, target, feature_Q5, null_hypothesis_Q5, alternative_hypothesis_Q5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d67b01",
   "metadata": {},
   "source": [
    "* positive class:  not churned\n",
    "* negative class:  churned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f148e1",
   "metadata": {},
   "source": [
    "# Decision Tree Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55626dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y(train, validate, test, target):\n",
    "    \"\"\"\n",
    "    This function creates x and y variables for either a decision tree or a random forest, \n",
    "    by using the unsplit df, target variable columns name and column to drop, for multiple columns that need to be \n",
    "    dropped create a list of the columns0\n",
    "    The arguments taken in are train, validate, test, target, drop_col=[])\n",
    "    The function returns x_train, y_train, x_validate, y_validate, x_test, y_test\n",
    "    \"\"\"\n",
    "    # separates train target variable\n",
    "    x_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "    # validate \n",
    "    x_validate = validate.drop(columns=[target])\n",
    "    y_validate = validate[target]\n",
    "\n",
    "    # test\n",
    "    x_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "    \n",
    "    return x_train, y_train, x_validate, y_validate, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada42a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_validate, y_validate, x_test, y_test = create_x_y(train, validate, test, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d730433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating baseline:  1's = churned & 0's = not churned  baseline accuracy = 0.7346745562130178\n",
    "# positive if not churned\n",
    "baseline_accuracy = (train.churn == 0).mean()\n",
    "baseline_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27354dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating baseline:  1's = churned & 0's = not churned  baseline accuracy = 0.7346745562130178\n",
    "# positive if not churned \n",
    "baseline_accuracy = (train.churn == 0).mean()\n",
    "baseline_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a function to get x & y variables for the split dataset\n",
    "drop_gender = [\"partner\", \"dependents\", \"paperless_billing\", \"automatic_payment\", \"churn\"]\n",
    "x_train, y_train, x_validate, y_validate, x_test, y_test = create_x_y(train_2[drop_gender], validate_2[drop_gender], test_2[drop_gender], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb61c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a function to get x & y variables for the split dataset\n",
    "drop_gender = [\"partner\", \"dependents\", \"paperless_billing\", \"automatic_payment\", \"churn\"]\n",
    "x_train_2, y_train_2, x_validate_2, y_validate_2, x_test_2, y_test_2 = create_x_y(train, validate, test, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object \n",
    "tree = DecisionTreeClassifier(random_state=3)\n",
    "\n",
    "# model.fit(x, y)\n",
    "tree = tree.fit(x_train, y_train)\n",
    "x_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object \n",
    "tree_2 = DecisionTreeClassifier(max_depth=3, random_state=3)\n",
    "\n",
    "# model.fit(x, y)\n",
    "tree_2 = tree_2.fit(x_train, y_train)\n",
    "\n",
    "# score for train = 0.7401183431952663 --- this is greater than the baseline\n",
    "train_accuracy_2 = tree_2.score(x_train, y_train)\n",
    "\n",
    "# score for validate = 0.7196593328601846 --- this is less than the baseline\n",
    "validate_accuracy_2 = tree_2.score(x_validate, y_validate)\n",
    "train_accuracy_2, validate_accuracy_2\n",
    "\n",
    "def dt_accuracy(tree, x_train, y_train, x_validate, y_validate):\n",
    "    '''\n",
    "    This function provides a quick print output of the train and validation scores based on your decision tree, for easy viewing.\n",
    "    The function takes the following arguments: tree, x_train, y_train, x_validate, y_validate\n",
    "    '''\n",
    "    print(f'''\n",
    "\n",
    "    Accuracy of Decision Tree classifier on training set: {round(tree.score(x_train, y_train),2)}\n",
    "    Accuracy of Decision Tree classifier on validation set: {round(tree.score(x_validate, y_validate),2)}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_accuracy(tree, x_train, y_train, x_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a39277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction on train obeservations\n",
    "y_pred = tree.predict(x_train)\n",
    "\n",
    "#estimate probablility \n",
    "y_pred_proba = tree.predict_proba(x_train)\n",
    "\n",
    "# create confusion matrix\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# nice dataframe with conf\n",
    "labels = sorted(y_train.unique())\n",
    "pd.DataFrame(conf,\n",
    "            index=[str(label) + '_actual'for label in labels],\n",
    "            columns=[str(label) + '_predict'for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_predict(tree, x_train, y_train):    \n",
    "    # make prediction on train obeservations\n",
    "    y_pred = tree.predict(x_train)\n",
    "\n",
    "    #estimate probablility \n",
    "\n",
    "\n",
    "    # create confusion matrix\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "    # nice dataframe with conf\n",
    "    labels = sorted(y_train.unique())\n",
    "    df = pd.DataFrame(conf,\n",
    "                index=[str(label) + '_actual'for label in labels],\n",
    "                columns=[str(label) + '_predict'for label in labels])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48d88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predict(tree_3, x_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd22135",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, FN, TN = conf.ravel()\n",
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check accuracy \n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43841ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores_all = []\n",
    "\n",
    "for x in range(1,20):\n",
    "\n",
    "    tree = DecisionTreeClassifier(max_depth=x)\n",
    "    tree.fit(x_train, y_train)\n",
    "    train_acc = tree.score(x_train, y_train)\n",
    "    \n",
    "    #evaluate on validate\n",
    "    val_acc = tree.score(x_validate, y_validate)\n",
    "    \n",
    "    scores_all.append([x, train_acc, val_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f84f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80187e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_depth(scores):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(scores.max_depth, scores.train_acc, label='train', marker='o')\n",
    "    plt.plot(scores.max_depth, scores.val_acc, label='validation', marker='o')\n",
    "    plt.xlabel('max depth')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('how does the accuracy change with max depth on train and validate?')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877eb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_check(x_train, y_train, x_validate, y_validate):\n",
    "    scores_all = []\n",
    "    for x in range(1,20):\n",
    "\n",
    "        tree = DecisionTreeClassifier(max_depth=x, random_state=3)\n",
    "        tree.fit(x_train, y_train)\n",
    "        train_acc = tree.score(x_train, y_train)\n",
    "\n",
    "        #evaluate on validate\n",
    "        val_acc = tree.score(x_validate, y_validate)\n",
    "\n",
    "        scores_all.append([round(x, 6), round(train_acc, 6), round(val_acc, 6)])\n",
    "        \n",
    "    scores = pd.DataFrame(scores_all, columns=['max_depth','train_acc','val_acc'])\n",
    "    \n",
    "    scores['diff'] = round(scores.train_acc - scores.val_acc, 6)\n",
    "    return scores\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_depth_graph(x_train, y_train, x_validate, y_validate):\n",
    "    '''\n",
    "    This function takes in: x_train, y_train, x_validate, y_validate\n",
    "    Which then runs through a range of (1,20) to help determine the best parameter for max_depth.\n",
    "    It outputs a visual graph and a table with the accuracy results and difference in score for better viewing. \n",
    "    '''\n",
    "\n",
    "    # create scoring table\n",
    "    scores = depth_check(x_train, y_train, x_validate, y_validate)\n",
    "\n",
    "\n",
    "    # creating graph\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    fig.suptitle('how does the accuracy change with max depth on train and validate?')\n",
    "    \n",
    "    ax1 = fig.add_subplot(121)\n",
    "    \n",
    "\n",
    "    ax1.plot(scores.max_depth, scores.train_acc, label='train', marker='o')\n",
    "    ax1.plot(scores.max_depth, scores.val_acc, label='validation', marker='o')\n",
    "\n",
    "    ax1.legend()\n",
    "\n",
    "#     Create visual table\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    font_size=9\n",
    "    bbox=[0, 0, 1, 1]\n",
    "    ax2.axis('off')\n",
    "    mpl_table = ax2.table(cellText = scores.values, rowLabels = scores.index, bbox=bbox, colLabels=scores.columns)\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f18407",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.dt_depth_graph(x_train, y_train, x_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366485ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = depth_check(x_train, y_train, x_validate, y_validate)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94426fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2 = depth_check(x_train_2, y_train_2, x_validate_2, y_validate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bad7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth(scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed max_depth to 3 because of prior results\n",
    "tree_2 = DecisionTreeClassifier(max_depth=3, random_state=3)\n",
    "\n",
    "# model.fit(x, y)\n",
    "tree_2 = tree_2.fit(x_train, y_train)\n",
    "\n",
    "# score for train = 0.7401183431952663 --- this is greater than the baseline\n",
    "train_accuracy_2 = tree_2.score(x_train, y_train)\n",
    "\n",
    "# score for validate = 0.7196593328601846 --- this is less than the baseline\n",
    "validate_accuracy_2 = tree_2.score(x_validate, y_validate)\n",
    "train_accuracy_2, validate_accuracy_2\n",
    "\n",
    "print(f'''\n",
    "\n",
    "Accuracy of Decision Tree classifier on training set: {round(tree_2.score(x_train, y_train),2)}\n",
    "Accuracy of Decision Tree classifier on validation set: {round(tree_2.score(x_validate, y_validate),2)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed max_depth to 3 because of prior results\n",
    "tree_3 = DecisionTreeClassifier(max_depth=5, random_state=3)\n",
    "\n",
    "# model.fit(x, y)\n",
    "tree_3 = tree_3.fit(x_train_2, y_train_2)\n",
    "\n",
    "# score for train = 0.7401183431952663 --- this is greater than the baseline\n",
    "train_accuracy_3 = tree_3.score(x_train_2, y_train_2)\n",
    "\n",
    "# score for validate = 0.7196593328601846 --- this is less than the baseline\n",
    "validate_accuracy_3 = tree_3.score(x_validate_2, y_validate_2)\n",
    "\n",
    "\n",
    "print(f'''\n",
    "\n",
    "Accuracy of Decision Tree classifier on training set: {round(tree_3.score(x_train_2, y_train_2),2)}\n",
    "Accuracy of Decision Tree classifier on validation set: {round(tree_3.score(x_validate_2, y_validate_2),2)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378592fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_tree(x_train, y_train, x_validate, y_validate):\n",
    "    tree = DecisionTreeClassifier(max_depth=3, random_state=3)\n",
    "\n",
    "    # model.fit(x, y)\n",
    "    tree = tree.fit(x_train, y_train)\n",
    "\n",
    "    # score for train\n",
    "    train_accuracy = tree.score(x_train, y_train)\n",
    "\n",
    "    # score for validate\n",
    "    validate_accuracy = tree.score(x_validate, y_validate)\n",
    "\n",
    "\n",
    "    print(f'''\n",
    "\n",
    "    Accuracy of Decision Tree classifier on training set: {round(tree.score(x_train, y_train),3)}\n",
    "    Accuracy of Decision Tree classifier on validation set: {round(tree.score(x_validate, y_validate),3)}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61055ad3",
   "metadata": {},
   "source": [
    "# Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.best_tree(x_train, y_train, x_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39117b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object\n",
    "rf = RandomForestClassifier(random_state=3)\n",
    "\n",
    "# fit model\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# evaluate feature importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prdictions\n",
    "y_pred_rf = rf.predict(x_train)\n",
    "\n",
    "# Estimate the probability\n",
    "y_pred_proba_rf = rf.predict_proba(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e064037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "conf_rf = confusion_matrix(y_train, y_pred_rf)\n",
    "\n",
    "# nice dataframe with conf\n",
    "labels = sorted(y_train.unique())\n",
    "pd.DataFrame(conf_rf,\n",
    "            index=[str(label) + '_actual'for label in labels],\n",
    "            columns=[str(label) + '_predict'for label in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model \n",
    "# rf train accuracy score = 0.7401183431952663\n",
    "rf.score(x_train, y_train)\n",
    "\n",
    "# rf  validate accuracy score = 0.7196593328601846\n",
    "rf.score(x_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bef434",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9de581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_check(x_train, y_train, x_validate, y_validate):\n",
    "    scores_all = []\n",
    "\n",
    "    for x in range(1,11):\n",
    "\n",
    "        #make it\n",
    "        rf = RandomForestClassifier(random_state=3, min_samples_leaf=x, max_depth=11-x)\n",
    "        #fit it\n",
    "        rf.fit(x_train, y_train)\n",
    "        #transform it\n",
    "        train_acc = rf.score(x_train, y_train)\n",
    "\n",
    "        #evaluate on my validate data\n",
    "        val_acc = rf.score(x_validate, y_validate)\n",
    "\n",
    "        scores_all.append([x, 11-x, round(train_acc, 4), round(val_acc, 4)])\n",
    "\n",
    "    scores_df = pd.DataFrame(scores_all, columns=['min_samples_leaf','max_depth','train_acc','val_acc'])\n",
    "    scores_df['difference'] = round(scores_df.train_acc - scores_df.val_acc, 3)\n",
    "    return scores_df\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b1279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_check2(x_train, y_train, x_validate, y_validate):\n",
    "    scores_all = []\n",
    "\n",
    "    for x in range(1,11):\n",
    "\n",
    "        #make it\n",
    "        rf = RandomForestClassifier(random_state=3, max_depth=x)\n",
    "        #fit it\n",
    "        rf.fit(x_train, y_train)\n",
    "        #transform it\n",
    "        train_acc = rf.score(x_train, y_train)\n",
    "\n",
    "        #evaluate on my validate data\n",
    "        val_acc = rf.score(x_validate, y_validate)\n",
    "\n",
    "        scores_all.append([x, round(train_acc, 4), round(val_acc, 4)])\n",
    "\n",
    "    scores_df = pd.DataFrame(scores_all, columns=['min_samples_leaf','train_acc','val_acc'])\n",
    "    scores_df['difference'] = round(scores_df.train_acc - scores_df.val_acc, 3)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2331d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leaf_check(x_train, y_train, x_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbaaf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_graph(scores_df):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(scores_df.max_depth, scores_df.train_acc, label='train', marker='o')\n",
    "    plt.plot(scores_df.max_depth, scores_df.val_acc, label='validation', marker='o')\n",
    "    plt.xlabel('max depth and min leaf sample')\n",
    "    plt.ylabel('accuracy')\n",
    "\n",
    "    plt.xticks([2,4,6,8,10],\n",
    "              [('2 and 9'),('4 and 7'),('6 and 5'),('8 and 4'),('10 and 2')]\n",
    "              )\n",
    "\n",
    "    plt.title('how does the accuracy change with max depth on train and validate?')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae86a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_leaf_graph(x_train, y_train, x_validate, y_validate):\n",
    "    '''\n",
    "    This function takes in: x_train, y_train, x_validate, y_validate\n",
    "    Which then runs through a range of (1,11)-min_samples_leaf and descending (1,11) for max_depth to help determine the best parameters\n",
    "    It outputs a visual graph and a table with the accuracy results and difference in score for better viewing. \n",
    "    '''\n",
    "\n",
    "    # create scoring table\n",
    "    scores = leaf_check(x_train, y_train, x_validate, y_validate)\n",
    "\n",
    "\n",
    "    # creating graph\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    fig.suptitle('how does the accuracy change with (min_samples_leaf asc. 1,11) and (max depth desc. 1,11) on train and validate?')\n",
    "    \n",
    "    ax1 = fig.add_subplot(121)\n",
    "    \n",
    "\n",
    "    ax1.plot(scores.max_depth, scores.train_acc, label='train', marker='o')\n",
    "    ax1.plot(scores.max_depth, scores.val_acc, label='validation', marker='o')\n",
    "    ax1.set_xlabel('max depth and min leaf sample')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.legend()\n",
    "\n",
    "#     Create visual table\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    font_size=9\n",
    "#     bbox=[0, 0, 1, 1]\n",
    "    ax2.axis('off')\n",
    "    mpl_table = ax2.table(cellText = scores.values, rowLabels = scores.index, bbox=bbox, colLabels=scores.columns)\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cfdc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_3 = leaf_check(x_train_2, y_train_2, x_validate_2, y_validate_2)\n",
    "scores_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_f = leaf_check2(x_train, y_train, x_validate, y_validate)\n",
    "scores_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae42b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_graph(scores_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed max_depth to 3 because of prior results\n",
    "rf_3 = RandomForestClassifier(random_state=3, max_depth=3)\n",
    "\n",
    "# model.fit(x, y)\n",
    "rf_3 = rf_3.fit(x_train_2, y_train_2)\n",
    "\n",
    "print(f'''\n",
    "\n",
    "Accuracy of Decision Tree classifier on training set: {round(rf_3.score(x_train_2, y_train_2),4)}\n",
    "Accuracy of Decision Tree classifier on validation set: {round(rf_3.score(x_validate_2, y_validate_2),4)}\n",
    "''')\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.best_forest(x_train, y_train, x_validate, y_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f75eb",
   "metadata": {},
   "source": [
    "# Logisitics Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object\n",
    "logit = LogisticRegression()\n",
    "\n",
    "# model fit \n",
    "logit.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51966327",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_2 = LogisticRegression()\n",
    "\n",
    "# model fit \n",
    "logit_2.fit(x_train_2, y_train_2)\n",
    "print(f'''\n",
    "    Accuracy of Logistic Regression classifier on training set: {round(logit_2.score(x_train_2, y_train_2),2)}\n",
    "    Accuracy of Logistic Regression classifier on validation set: {round(logit_2.score(x_validate_2, y_validate_2),2)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_accuracy(clf, x_train, y_train, x_validate, y_validate):\n",
    "    '''\n",
    "    This function provides a quick print output of the train and validation scores based on your decision tree, for easy viewing.\n",
    "    The function takes the following arguments: object name (clf), x_train, y_train, x_validate, y_validate\n",
    "    '''\n",
    "    print(f'''\n",
    "    Accuracy of {clf} on training set: {round(clf.score(x_train, y_train), 3)}\n",
    "    Accuracy of {clf} on validation set: {round(clf.score(x_validate, y_validate), 3)}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy(rf, x_train_2, y_train_2, x_validate_2, y_validate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf27089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate importance of each feature\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b98445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_lr = logit.predict(x_train)\n",
    "y_pred_proba_lr = logit.predict_proba(x_train)\n",
    "# compute accuracy\n",
    "print(f'''\n",
    "    Accuracy of Logistic Regression classifier on training set: {round(logit.score(x_train, y_train),2)}\n",
    "    Accuracy of Logistic Regression classifier on validation set: {round(logit.score(x_validate, y_validate),2)}\n",
    "''')\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21344dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clf_predict(clf, x_train, y_train): \n",
    "    '''\n",
    "    This function takes in the following arguments: tree, x_train, y_train\n",
    "    Then uses the arguments to make predictions on the train observation,\n",
    "    creating a matrix and a df of the matrix \n",
    "    '''   \n",
    "    # make prediction on train obeservations\n",
    "    y_pred = clf.predict(x_train)\n",
    "\n",
    "    # create confusion matrix\n",
    "    conf = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "    # nice dataframe with conf\n",
    "    labels = sorted(y_train.unique())\n",
    "    df = pd.DataFrame(conf,\n",
    "                index=[str(label) + '_actual'for label in labels],\n",
    "                columns=[str(label) + '_predict'for label in labels])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37aab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_predict(rf_3, x_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2730de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_predict(logit, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370854f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred_lr))\n",
    "y_pred_proba_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a71422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize #################################\n",
    "# create array of probabilities of churning\n",
    "\n",
    "y_pred_proba_churn = np.array([i[1] for i in y_pred_proba_lr])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "\n",
    "# scatter plot where x is the probabilities and y is the churn (0, 1)\n",
    "ax.scatter(y_pred_proba_churn, y_pred_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_churn[y_pred_proba_churn > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7907967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "print(f'''\n",
    "    Accuracy of Logistic Regression classifier on training set: {round(logit.score(x_train, y_train),2)}\n",
    "    Accuracy of Logistic Regression classifier on validation set: {round(logit.score(x_validate, y_validate),2)}\n",
    "    Accuracy of Logistic Regression classifier on test set: {round(logit.score(x_test, y_test),2)}\n",
    "    \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model 2\n",
    "print(f'''\n",
    "    Accuracy of Random Forest classifier on training set: {round(rf_3.score(x_train, y_train),2)}\n",
    "    Accuracy of Random Forest classifier on validation set: {round(rf_3.score(x_validate_2, y_validate_2),2)}\n",
    "    Accuracy of Random Forest  classifier on test set: {round(rf_3.score(x_test_2, y_test_2),2)}\n",
    "    \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_test(clf, x_train, y_train, x_validate, y_validate, x_test, y_test):\n",
    "    '''\n",
    "    ! WARNING!: Only use this for your final model \n",
    "    This function provides a quick print output of the baseling accuracy train, validation, test scores based on your classifier, for easy viewing.\n",
    "    The function takes the following arguments: object name (clf), x_train, y_train, x_validate, y_validate, x_test, y_test\n",
    "    '''\n",
    "    print(f'''\n",
    "    Baseline Accuracy: {round(baseline_accuracy, 3)}\n",
    "    Accuracy of {clf} on training set: {round(clf.score(x_train, y_train), 3)}\n",
    "    Accuracy of {clf} on validation set: {round(clf.score(x_validate, y_validate), 3)}\n",
    "    Accuracy of {clf} on test set: {round(clf.score(x_test, y_test), 3)}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68fcbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_test(logit, x_train, y_train, x_validate, y_validate, x_test, y_test, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee10c9",
   "metadata": {},
   "source": [
    "# KNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83944a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8998573",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.clf_accuracy(knn, x_train, y_train, x_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.clf_predict(knn, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0494acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    scores.append(knn.score(x_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "\n",
    "plt.show()\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1186c",
   "metadata": {},
   "source": [
    "# Final test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f91c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.best_model(x_train, y_train, x_validate, y_validate, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e661b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv with test model and predictions\n",
    "\n",
    "rf = RandomForestClassifier(random_state=3, max_depth=3)\n",
    "rf = rf.fit(x_train, y_train)\n",
    "test_pred = rf.predict(x_test)\n",
    "\n",
    "y_pred_proba = rf.predict_proba(x_test)\n",
    "\n",
    "prob_of_churn = y_pred_proba[:,1]\n",
    "test_pred\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efd93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=3, max_depth=3)\n",
    "rf = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv with test model and predictions\n",
    "\n",
    "\n",
    "test_pred = rf.predict(x_test)\n",
    "\n",
    "y_pred_proba = rf.predict_proba(x_test)\n",
    "\n",
    "prob_of_churn = y_pred_proba[:,1]\n",
    "test_pred\n",
    "\n",
    "prob_of_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cdf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with customer_id , probability of churn, and prediction\n",
    "prediction_df = pd.DataFrame({'customer_id': tt.customer_id,\n",
    "                              'probability_of_churn': rf.predict_proba(x_test)[:,1],\n",
    "                              'prediction_of_churn': rf.predict(x_test)})\n",
    "prediction_df.to_csv(\"prediction_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a812f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43946fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f843de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = tt[[\"customer_id\"]]\n",
    "test_pred = pd.DataFrame(rf.predict(x_test))\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82204b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6160d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68bed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([test_id, test_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae03ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_csv(tt, x_train, y_train, x_test, y_test):\n",
    "    rf = RandomForestClassifier(random_state=3, max_depth=3)\n",
    "    rf = rf.fit(x_train, y_train)\n",
    "    prediction_df = pd.DataFrame({'customer_id': tt.customer_id,\n",
    "                              'probability_of_churn': rf.predict_proba(x_test)[:,1],\n",
    "                              'prediction_of_churn': rf.predict(x_test)})\n",
    "    prediction_df.to_csv(\"prediction_df.csv\")\n",
    "    print(rf.predict(x_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_csv(tt, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40680b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c3d6ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_telco_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bf/lhpb5n_j1xj4msxy6nrm9h7h0000gn/T/ipykernel_18722/1694627146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mprep_telco2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_telco_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     '''\n\u001b[1;32m      3\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mclean\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtelco\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0mprior\u001b[0m \u001b[0mto\u001b[0m \u001b[0mexplore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mwill\u001b[0m \u001b[0malso\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     '''\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_telco_data' is not defined"
     ]
    }
   ],
   "source": [
    "def prep_telco2(df=get_telco_data(directory=os.getcwd())):\n",
    "    '''\n",
    "    The function will clean the telco dataset with features prior to explore.\n",
    "    The function will also return to dataframes:\n",
    "    '''\n",
    "    # encoding payment type automatic payment equals 1 and non_automatic equals 0\n",
    "    df[\"automatic_payment\"] = df[\"payment_type\"].map({\"Bank transfer (automatic)\": 1, \"Credit card (automatic)\": 1, \"Mailed check\": 0, \"Electronic check\": 0})\n",
    "\n",
    "    # create dummies\n",
    "    dummy_df = pd.get_dummies(df[[\"partner\",\n",
    "                                 \"dependents\", \n",
    "                                 \"paperless_billing\", \n",
    "                                 \"gender\",\n",
    "                                 \"churn\"]],\n",
    "                              drop_first=True)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "    # rename columns\n",
    "    df = df[[\"customer_id\",\"partner_Yes\", \"dependents_Yes\", \"paperless_billing_Yes\", \"automatic_payment\", \"churn_Yes\", \"gender_Male\", \"tenure\"]]\n",
    "    \n",
    "    df = df.rename(columns={\"partner_Yes\": \"partner\", \"dependents_Yes\": \"dependents\", \"paperless_billing_Yes\": \"paperless_billing\",  \"gender_Male\": \"gender\",\"churn_Yes\": \"churn\"})\n",
    "    # df for modeling\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ead5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
