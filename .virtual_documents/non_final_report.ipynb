import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# sklearn imports
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# tree classifier
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree

# rainforest classifier
from sklearn.ensemble import RandomForestClassifier

# linear regession classifier
from sklearn.linear_model import LogisticRegression

import wrangle as w



# # acquiring, cleaning, and adding features to data
df = w.get_telco_data()
# df = w.prep_telco()


df


# Get information about df, such as column names, rows, datatypes, non-missing values
df.info()


# Get summary statistics for numeric columns.
df.describe().T


# Use .describe with object columns.

obj_cols = df.columns[[df[col].dtype == 'O' for col in df.columns]]
for col in obj_cols:
    print(df[col].value_counts())
    print(df[col].value_counts(normalize=True, dropna=False))
    print('----------------------')



# Find columns with nulls and the total of missing values.
missing = df.isnull().sum()
missing[missing > 0]


# Drop duplicates, reassign and check the shape of df. *No change to df shape
df = df.drop_duplicates()
df.shape


df = w.prep_telco_2()
df


# encoding payment type automatic payment equals 1 and non_automatic equals 0
df["payment_encoded"] = df.payment_type.map({"Bank transfer (automatic)": 1, "Credit card (automatic)": 1, "Mailed check": 0, "Electronic check": 0})


df.payment_encoded.value_counts()


df.payment_type.value_counts()


df1 = df[["partner_Yes", "dependents_Yes", "paperless_billing_Yes", "payment_encoded", "churn_Yes"]]


df1


# cleaning column names for easier recall and because it's formal
df1 = df1.rename(columns={"partner_Yes": "partner", "dependents_Yes": "dependents", "paperless_billing_Yes": "paperless_billing", "payment_encoded": "automatic_payment", "churn_Yes": "churn" })


target = "churn"


train, validate, test = w.split_data(df1,target)


# Validate split.
def valid_split(train, validate, test):
    print(f'train -> {train.shape}')
    print(f'validate -> {validate.shape}')
    print(f'test -> {test.shape}')


valid_split(train, validate, test)


train.info()


train.head()


plt.title("What's the Relationship Between Churn and Automatic Payment Type?")
sns.barplot(x="automatic_payment", y="churn", data=train)
population_churn_rate = train.churn.mean()
plt.axhline(population_churn_rate, label="Population Churn Rate")
plt.legend()
plt.show()


# Setup a crosstab of observed survival to pclass
def cross_function(train, target_variable, feature_variable, null_hypothesis, alternative_hypothesis):
    '''
    This function will take the train df, target_variable, and feature_variable
    '''
    observed = pd.crosstab(train[target_variable], train[feature_variable])

    chi2, p, degf, expected = stats.chi2_contingency(observed)

    if p < alpha:
        print(f"Reject the null hypothesis: {null_hypothesis}")
        print(f"Sufficient evidence to move forward understanding that, {alternative_hypothesis}")
    else:
        print("Fail to reject the null")
        print("Insufficient evidence to reject the null")
    return p


# Chi squared to compare proportions, define confidence
alpha_Q1 = 0.05
target_Q1 = "churn"
feature_variable_Q1 = "automatic_payment"
null_hypothesis_Q1 = "churn and automatic payment are independent"
alternative_hypothesis_Q1 = "there is a relationship between automatic payment and churn"

cross_function(train, target, feature_variable_Q1, null_hypothesis_Q1, alternative_hypothesis_Q1)





plt.title("What's the Relationship Between Churn and paperless billing?")
sns.barplot(x="paperless_billing", y="churn", data=train)
population_churn_rate = train.churn.mean()
plt.axhline(population_churn_rate, label="Population Churn Rate")
plt.legend()
plt.show()


# Chi squared to compare proportions, define confidence
alpha_Q2 = 0.05
target_Q2 = "churn"
feature_variable_Q2 = "paperless_billing"
null_hypothesis_Q2 = "churn and paperless_billing are independent"
alternative_hypothesis_Q2 = "there is a relationship between paperless_billing and churn"

cross_function(train, target, feature_variable_Q2, null_hypothesis_Q2, alternative_hypothesis_Q2)


plt.title("What's the Relationship Between Churn and Customers' with Partners")
sns.barplot(x="partner", y="churn", data=train)
population_churn_rate = train.churn.mean()
plt.axhline(population_churn_rate, label="Population Churn Rate")
plt.legend()
plt.show()


# Chi squared to compare proportions, define confidence
alpha_Q3 = 0.05
target_Q3 = "churn"
feature_variable_Q3 = "partner"
null_hypothesis_Q3 = "churn and customers' with partners are independent"
alternative_hypothesis_Q3 = "there is a relationship between customers' with partners and churn"

cross_function(train, target, feature_variable_Q3, null_hypothesis_Q3, alternative_hypothesis_Q3)


plt.title("What's the Relationship Between Churn and Customers' with Dependents")
sns.barplot(x="dependents", y="churn", data=train)
population_churn_rate = train.churn.mean()
plt.axhline(population_churn_rate, label="Population Churn Rate")
plt.legend()
plt.show()


alpha_Q4 = 0.05
target_Q4 = "churn"
feature_variable_Q4 = "dependents"
null_hypothesis_Q4 = "churn and customers' with dependents are independent"
alternative_hypothesis_Q4 = "there is a relationship between customers' with dependents and churn"

cross_function(train, target, feature_variable_Q4, null_hypothesis_Q4, alternative_hypothesis_Q4)


def create_x_y(train, validate, test, target):
    """
    This function creates x and y variables for either a decision tree or a random forest, 
    by using the unsplit df, target variable columns name and column to drop, for multiple columns that need to be 
    dropped create a list of the columns0
    The arguments taken in are train, validate, test, target, drop_col=[])
    The function returns x_train, y_train, x_validate, y_validate, x_test, y_test
    """
    # separates train target variable
    x_train = train.drop(columns=[target])
    y_train = train[target]
    # validate 
    x_validate = validate.drop(columns=[target])
    y_validate = validate[target]

    # test
    x_test = test.drop(columns=[target])
    y_test = test[target]
    
    return x_train, y_train, x_validate, y_validate, x_test, y_test


# creating baseline:  1's = churned & 0's = not churned  baseline accuracy = 0.7346745562130178
# positive if not churned
baseline_accuracy = (train.churn == 0).mean()
baseline_accuracy



# using a function to get x & y variables for the split dataset
x_train, y_train, x_validate, y_validate, x_test, y_test = create_x_y(train, validate, test, target)


# create object 
tree = DecisionTreeClassifier(random_state=3)

# model.fit(x, y)
tree = tree.fit(x_train, y_train)

# score for train = 0.7401183431952663 --- this is greater than the baseline
train_accuracy = tree.score(x_train, y_train)

# score for validate = 0.7196593328601846 --- this is less than the baseline
validate_accuracy = tree.score(x_validate, y_validate)
validate_accuracy


# make prediction on train obeservations
y_pred = tree.predict(x_train)

#estimate probablility 
y_pred_proba = tree.predict_proba(x_train)


# create confusion matrix
conf = confusion_matrix(y_train, y_pred)

# nice dataframe with conf
labels = sorted(y_train.unique())
pd.DataFrame(conf,
            index=[str(label) + '_actual'for label in labels],
            columns=[str(label) + '_predict'for label in labels])


TP, FP, FN, TN = conf.ravel()
TP


# check accuracy 
accuracy_score(y_train, y_pred)


# create object
rf = RandomForestClassifier(random_state=3)

# fit model
rf.fit(x_train, y_train)

# evaluate feature importance
print(rf.feature_importances_)


# create prdictions
y_pred_rf = rf.predict(x_train)

# Estimate the probability
y_pred_proba_rf = rf.predict_proba(x_train)



# create confusion matrix
conf_rf = confusion_matrix(y_train, y_pred_rf)

# nice dataframe with conf
labels = sorted(y_train.unique())
pd.DataFrame(conf_rf,
            index=[str(label) + '_actual'for label in labels],
            columns=[str(label) + '_predict'for label in labels])



print(classification_report(y_train, y_pred_rf))


# evaluate model 
# rf train accuracy score = 0.7401183431952663
rf.score(x_train, y_train)

# rf  validate accuracy score = 0.7196593328601846
rf.score(x_validate, y_validate)


# create object
logit = LogisticRegression()

# model fit 
logit.fit(x_train, y_train)


# evaluate importance of each feature
print('Coefficient: \n', logit.coef_)
print('Intercept: \n', logit.intercept_)



# make predictions
y_pred_lr = logit.predict(x_train)
y_pred_proba_lr = logit.predict_proba(x_train)
# compute accuracy
print(f'''
    Accuracy of Logistic Regression classifier on training set: {round(logit.score(x_train, y_train),2)}
    Accuracy of Logistic Regression classifier on validation set: {round(logit.score(x_validate, y_validate),2)}
''')

print(confusion_matrix(y_train, y_pred_lr))



# classification report
print(classification_report(y_train, y_pred_lr))
y_pred_proba_lr


# Visualize #################################
# create array of probabilities of churning

y_pred_proba_churn = np.array([i[1] for i in y_pred_proba_lr])

fig = plt.figure()
plt.figure(figsize=(10,6))
ax = fig.add_subplot()


# scatter plot where x is the probabilities and y is the churn (0, 1)
ax.scatter(y_pred_proba_churn, y_pred_lr)



y_pred_proba_churn[y_pred_proba_churn > 0.5]


# Test Model
print(f'''
    Accuracy of Logistic Regression classifier on training set: {round(logit.score(x_train, y_train),2)}
    Accuracy of Logistic Regression classifier on validation set: {round(logit.score(x_validate, y_validate),2)}
    Accuracy of Logistic Regression classifier on test set: {round(logit.score(x_test, y_test),2)}
    
''')



